# METHODE 1: stockage des données dans HDFS AVEC INSERTION DANS HIVE
-----------------------------------------------------------
...#
        if consent:
            feedback = Feedback(bootcamp, feedback_type, date, rating, comment)

            try:
                # Écrire les données dans HDFS
                hdfs = PyWebHdfsClient(host='localhost', port='9870', user_name='hdfs')
                hdfs.append_file('/user/hdfs/feedbacks.csv', f"{bootcamp},{feedback_type},{date},{rating},'{comment}'\n", append=True)

                # Insérer les données dans Hive
                conn = hive.Connection(host="localhost", port=10000, database="lplearning", auth='NONE', username='hdfs')
                cursor = conn.cursor()

                query = f"INSERT INTO feedbacks (bootcamp, feedback_type, `date`, rating, comment) VALUES ('{bootcamp}', '{feedback_type}', '{date}', {rating}, '{comment}')"
                cursor.execute(query)

                conn.close()

                # créer un message Flash 
                flash("Merci pour votre contribution ! votre retour a été enregistré.", "success")  
                return redirect(url_for('routes.home'))           
                
            except Exception as e:
                print(f"Erreur lors de l'enregistrement du feedback : {str(e)}")
                flash("Une erreur est survenue. Veuillez réessayer plus tard.", "danger")   
                return redirect(url_for('routes.home'))

        else:
            flash("Veuillez donner votre consentement pour enregistrer votre retour.", "warning")
            return redirect(url_for('routes.home'))
    
    return render_template('index.html')


... # 

# METHODE 2 : UTILISATION DE SUBPROCESS, POPEN et PIPE
# ...

...
from subprocess import Popen, PIPE


bp = Blueprint('routes', __name__)

# '/' : Route pour la page d'accueil qui affiche le formulaire de retour et 
#       gère la soumission des nouveaux retours.
@bp.route('/', methods=['GET', 'POST'])
def home():
    if request.method == 'POST':
        bootcamp = request.form['formation']
        feedback_type = request.form['typeRetour']
        date = request.form['date']
        rating = int(request.form['rating'])
        comment = request.form['comments']
        consent = 'consentement' in request.form
        
        if consent:
            feedback = Feedback(bootcamp, feedback_type, date, rating, comment)

            try:
                # Enregistrer le retour dans un fichier CSV temporaire
                with open('temp_feedback.csv', 'w', newline='') as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow([1, bootcamp, feedback_type, date, rating, comment])

                # Charger le fichier CSV dans HDFS 
                put = Popen(["hadoop", "fs", "-put", "temp_feedback.csv", "/feedbacks"], stdin=PIPE, bufsize=-1, shell= True)
                put.communicate()
                

                # créer un message Flash 
                flash("Merci pour votre contribution ! votre retour a été enregistré.", "success")  
                return redirect(url_for('routes.home'))           
                
            except Exception as e:
                print(f"Erreur lors de l'enregistrement du feedback : {str(e)}")
                flash("Une erreur est survenue. Veuillez réessayer plus tard.", "danger")   
                return redirect(url_for('routes.home'))

        else:
            flash("Veuillez donner votre consentement pour enregistrer votre retour.", "warning")
            return redirect(url_for('routes.home'))
    
    return render_template('index.html')

    # ...

    # Chargement des données dans la table Hive:
    Dans CLI Hive : 
    LOAD DATA INPATH 'feedbacks/temp_feedback.csv' INTO TABLE feedbacks;


# Créer un table HIVE:
CREATE EXTERNAL TABLE feedbacks (
  id INT,
  bootcamp STRING,
  feedback_type STRING,
  `date` STRING,
  rating INT,
  comment STRING
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n' 
STORED AS TEXTFILE
LOCATION '/user/hdfs/';

For internal table: LOAD DATA INPATH '/user/hdfs/feedbacks.csv' INTO TABLE feedbacks;


# METHODE POUR GENERER ID dans HIVE 
try: ...
    conn = hive.Connection(host="localhost", port=10000, database="lplearning")
    cursor = conn.cursor()

    # Générer un UUID unique pour le nouveau feedback
    feedback_id = str(uuid.uuid4())

    query = "INSERT INTO feedbacks (id, bootcamp, feedback_type, date, rating, comment) VALUES (%s, %s, %s, %s, %s, %s)"
    cursor.execute(query, (feedback_id, bootcamp, feedback_type, date, rating, comment))

    conn.close()

    flash(...)
    return ...

# Dans la prochaine étape, nous verrons comment récupérer et afficher ces données dans notre application web.


def get_last_id_from_csv():
    """ Cette fonction lit le dernier ID utilisé dans le fichier CSV stocké sur HDFS """
    try:
        hdfs = PyWebHdfsClient(host='localhost', port='9870', user_name='hdfs')
        # Get the file content
        file_content = hdfs.read_file('/user/hdfs/feedbacks.csv')
        # Assuming file_content is a bytes object, decode it to a string
        file_str = file_content.decode('utf-8')
        # Split the file content into lines and get the last line
        last_line = file_str.strip().split('\n')[-1]
        last_id = int(last_line.split(',')[0])
        return last_id
    except FileNotFoundError:
        return 0
    except Exception as e:
        print(f"Erreur lors de la lecture du fichier CSV : {str(e)}")
        return 0


###########################################

## Methode pour ajouter les nouveaux retour dans hive depuis hdfs sans risque de duplication

# Creer une nouvelle table:

1/
CREATE TABLE temp_feedbacks (
    les memes colonnes ...
);
 
2/
LOAD DATA LOCAL INPATH '/user/hdfs/feedbacks.csv' INTO TABLE temp_feedbacks

3/
INSERT INTO feedbacks
SELECT *
FROM temp_feedbacks
WHERE id > (SELECT MAX(id) FROM feedbacks);

4/
DROP TABLE temp_feedbacks;

